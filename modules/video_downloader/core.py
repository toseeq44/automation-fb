"""Core implementation for the smart video downloader."""

import os
import subprocess
import re
import time
import random
from datetime import datetime, timedelta
from pathlib import Path
from typing import Optional

import yt_dlp
from PyQt5.QtCore import QThread, pyqtSignal

from .url_utils import (
    coerce_bool,
    extract_urls,
    normalize_url,
    quality_to_format,
)
from .history_manager import HistoryManager
from .instagram_helper import (
    InstagramCookieValidator,
    get_instagram_cookie_instructions,
    test_instagram_cookies,
)

# ===================== HELPERS ====================

def _detect_platform(url: str) -> str:
    url = url.lower()
    if 'tiktok.com' in url: return 'tiktok'
    if 'youtube.com' in url or 'youtu.be' in url: return 'youtube'
    if 'instagram.com' in url: return 'instagram'
    if 'facebook.com' in url or 'fb.com' in url: return 'facebook'
    if 'twitter.com' in url or 'x.com' in url: return 'twitter'
    return 'other'

def _get_random_user_agent() -> str:
    """Get random user agent to avoid detection"""
    user_agents = [
        # Real mobile browsers
        'Mozilla/5.0 (iPhone; CPU iPhone OS 16_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.6 Mobile/15E148 Safari/604.1',
        'Mozilla/5.0 (Linux; Android 13; SM-S901B) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Mobile Safari/537.36',
        'Mozilla/5.0 (Linux; Android 13; Pixel 7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Mobile Safari/537.36',
        # TikTok app user agents (more realistic)
        'com.zhiliaoapp.musically/2023405020 (Linux; U; Android 13; en_US; Pixel 7; Build/TP1A.220624.014; Cronet/TTNetVersion:7d6d3f56 2023-03-22 QuicVersion:47946a6c 2023-01-18)',
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    ]
    return random.choice(user_agents)

def _is_ip_block_error(error_text: str) -> bool:
    """Detect if error is due to IP blocking"""
    if not error_text:
        return False

    # Remove ANSI color codes (e.g., [0;31m, [0m)
    import re
    clean_text = re.sub(r'\x1b\[[0-9;]*m', '', error_text)
    clean_text = clean_text.lower()

    ip_block_indicators = [
        'ip address is blocked',
        'ip blocked',
        'access denied',
        '403 forbidden',
        'not available in your country',
        'video is not available',
        'this video isn\'t available',
        'region',
    ]

    return any(indicator in clean_text for indicator in ip_block_indicators)

# ===================== MAIN THREAD ====================
class VideoDownloaderThread(QThread):
    progress = pyqtSignal(str)
    progress_percent = pyqtSignal(int)
    download_speed = pyqtSignal(str)
    eta = pyqtSignal(str)
    finished = pyqtSignal(bool, str)
    video_complete = pyqtSignal(str)

    # default safeguards so attribute lookups never explode even if init fails mid-way
    skip_recent_window = True

    def __init__(self, urls, save_path, options, parent=None, bulk_mode_data=None):
        super().__init__(parent)
        # Accept flexible input for URLs (string, list, dicts from Link Grabber, etc.)
        self.urls = extract_urls(urls)
        self.save_path = save_path
        # Ensure options behave like a dict so feature flags don't break older callers
        if options is None:
            self.options = {}
        elif isinstance(options, dict):
            self.options = options
        else:
            # Some legacy callers pass QVariants/objects â€“ fall back to empty dict but keep reference
            try:
                self.options = dict(options)
            except Exception:
                self.options = {}
        self.cancelled = False
        self.success_count = 0
        self.skipped_count = 0
        self.skip_recent_window = coerce_bool(
            self.options.get('skip_recent_window'),
            default=self.skip_recent_window,
        )
        self.max_retries = self.options.get('max_retries', 3)
        self.force_all_methods = bool(self.options.get('force_all_methods', False))
        # Map quality preference to yt-dlp format selection if caller didn't supply one
        format_override = self.options.get('format')
        if not format_override:
            quality_pref = self.options.get('quality')
            format_override = quality_to_format(quality_pref)
        self.format_override = format_override

        # Proxy configuration (for IP block bypass) - ENHANCED
        # Priority: Options â†’ Link Grabber config â†’ Environment variable
        self.proxies = self._load_proxies_from_config()
        self.current_proxy_index = 0
        self.proxy_url = self.options.get('proxy_url', os.environ.get('HTTPS_PROXY', ''))  # Legacy support

        # Rate limiting (to avoid triggering IP blocks)
        self.last_request_times = {}  # domain -> timestamp
        self.rate_limit_delay = self.options.get('rate_limit_delay', 2.5)  # seconds between requests

        # Failed URLs tracking (for detailed error reporting)
        self.failed_urls = []  # [(url, reason)]

        # Bulk mode support
        self.bulk_mode_data = bulk_mode_data
        self.history_manager = None
        self.is_bulk_mode = bulk_mode_data and bulk_mode_data.get('enabled')

        if self.is_bulk_mode:
            self.history_manager = bulk_mode_data.get('history_manager')
            self.bulk_creators = bulk_mode_data.get('creators', {})
            # Only create tracking files in bulk mode
            self.downloaded_links_file = Path(save_path) / ".downloaded_links.txt"
            self.downloaded_links = self._load_downloaded_links()
        else:
            # Single mode: NO tracking files
            self.bulk_creators = {}
            self.downloaded_links_file = None
            self.downloaded_links = set()

    def _load_downloaded_links(self) -> set:
        """Load downloaded links (bulk mode only)"""
        if not self.is_bulk_mode or not self.downloaded_links_file:
            return set()  # Single mode: never load files

        try:
            if self.downloaded_links_file.exists():
                with open(self.downloaded_links_file, 'r', encoding='utf-8') as f:
                    return set(line.strip() for line in f if line.strip())
        except Exception:
            pass
        return set()

    def _mark_as_downloaded(self, url: str):
        """Mark URL as downloaded (bulk mode only)"""
        # TRIPLE SAFETY CHECK: Never create files in single mode!
        if not self.is_bulk_mode:
            return  # Single mode: NO file operations

        if not self.downloaded_links_file:
            return  # Extra safety: no file path set

        try:
            normalized = normalize_url(url)
            self.downloaded_links.add(normalized)

            # Write to file (only in bulk mode)
            with open(self.downloaded_links_file, 'a', encoding='utf-8') as f:
                f.write(f"{normalized}\n")
        except Exception as e:
            self.progress.emit(f"âš ï¸ Could not save download record: {str(e)[:50]}")

    def _is_already_downloaded(self, url: str) -> bool:
        """Check if already downloaded (bulk mode only)"""
        if not self.is_bulk_mode:
            return False  # Never skip in single mode

        normalized = normalize_url(url)
        return normalized in self.downloaded_links

    def _load_proxies_from_config(self) -> list:
        """
        Load proxy settings from Link Grabber's config file.

        Priority:
        1. Link Grabber config (config/proxy_settings.json)
        2. Empty list (no proxies)

        Returns:
            list: List of parsed proxy URLs ready to use
        """
        try:
            from modules.config.paths import get_config_dir
            import json

            config_file = get_config_dir() / "proxy_settings.json"

            if not config_file.exists():
                return []

            with open(config_file, 'r', encoding='utf-8') as f:
                settings = json.load(f)

            proxies = []

            # Load proxy1
            proxy1 = settings.get('proxy1', '').strip()
            if proxy1:
                parsed = self._parse_proxy_format(proxy1)
                if parsed:
                    proxies.append(parsed)

            # Load proxy2
            proxy2 = settings.get('proxy2', '').strip()
            if proxy2:
                parsed = self._parse_proxy_format(proxy2)
                if parsed:
                    proxies.append(parsed)

            return proxies

        except Exception:
            return []

    def _parse_proxy_format(self, proxy: str) -> str:
        """
        Parse and convert proxy format to standard format.
        Copied from Link Grabber for consistency.

        Supports 3 formats:
        1. ip:port                        â†’ http://ip:port
        2. user:pass@ip:port              â†’ http://user:pass@ip:port
        3. ip:port:user:pass (provider)   â†’ http://user:pass@ip:port

        Args:
            proxy: Proxy string in any supported format

        Returns:
            Standardized proxy URL (http://...)
        """
        try:
            proxy = proxy.strip()

            # If already has protocol, return as-is
            if proxy.startswith('http://') or proxy.startswith('https://') or proxy.startswith('socks'):
                return proxy

            # Check for @ symbol (standard format: user:pass@ip:port)
            if '@' in proxy:
                return f"http://{proxy}"

            # Split by colon to check format
            parts = proxy.split(':')

            if len(parts) == 4:
                # Format: ip:port:user:pass (provider format)
                ip, port, user, password = parts
                return f"http://{user}:{password}@{ip}:{port}"

            elif len(parts) == 2:
                # Format: ip:port (no auth)
                return f"http://{proxy}"

            else:
                return ""

        except Exception:
            return ""

    def _get_current_proxy(self) -> Optional[str]:
        """
        Get current proxy from the pool.

        Returns:
            str: Current proxy URL or None if no proxies available
        """
        if not self.proxies:
            return None

        return self.proxies[self.current_proxy_index]

    def _rotate_proxy(self):
        """Switch to next proxy in the pool (circular rotation)"""
        if len(self.proxies) > 1:
            self.current_proxy_index = (self.current_proxy_index + 1) % len(self.proxies)
            self.progress.emit(f"   ğŸ”„ Switched to proxy {self.current_proxy_index + 1}/{len(self.proxies)}")
            return True
        return False

    def _apply_rate_limit(self, domain: str):
        """Apply rate limiting to avoid triggering IP blocks"""
        if domain not in self.last_request_times:
            self.last_request_times[domain] = time.time()
            return

        now = time.time()
        elapsed = now - self.last_request_times[domain]

        if elapsed < self.rate_limit_delay:
            wait_time = self.rate_limit_delay - elapsed
            if wait_time > 0.1:  # Only show message if waiting more than 100ms
                self.progress.emit(f"   â³ Rate limiting: waiting {wait_time:.1f}s...")
            time.sleep(wait_time)

        self.last_request_times[domain] = time.time()

    # Removed old timestamp logic - now using history.json only

    def _get_ytdlp_command(self):
        """
        Get yt-dlp command with smart detection and fallbacks.

        Priority:
        1. Bundled with EXE (OneSoul/_internal/yt-dlp.exe)
        2. System PATH (yt-dlp or yt-dlp.exe)
        3. Common Windows install locations
        4. None (use Python library API as final fallback)

        Returns:
            str or None: Command to use, or None to trigger Python API fallback
        """
        # Cache the result to avoid repeated lookups
        if hasattr(self, '_ytdlp_cmd_cache'):
            return self._ytdlp_cmd_cache

        try:
            from modules.config.paths import find_ytdlp_executable
            cmd = find_ytdlp_executable()
            self._ytdlp_cmd_cache = cmd
            return cmd
        except Exception:
            self._ytdlp_cmd_cache = None
            return None

    def _cleanup_tracking_files(self, folder_path: str):
        """Remove any leftover tracking files (for single mode cleanup)"""
        if self.is_bulk_mode:
            return  # Don't cleanup in bulk mode

        try:
            folder = Path(folder_path)
            if not folder.exists():
                return

            # Remove old tracking files if they exist
            tracking_files = [
                '.downloaded_links.txt',
                '.last_download_time.txt',
                '.download_history.txt',  # Any other variants
            ]

            for filename in tracking_files:
                file_path = folder / filename
                if file_path.exists():
                    file_path.unlink()
                    self.progress.emit(f"ğŸ§¹ Removed leftover file: {filename}")

        except Exception as e:
            # Silent fail - not critical
            pass

    def _remove_from_source_txt(self, url: str, source_folder: str):
        """Remove URL from source txt file (bulk mode only)"""
        if not self.is_bulk_mode:
            return  # Skip in single mode

        try:
            source_path = Path(source_folder)
            if not source_path.exists(): return
            for txt_file in source_path.glob("*.txt"):
                if txt_file.name.startswith('.'): continue
                try:
                    with open(txt_file, 'r', encoding='utf-8', errors='ignore') as f:
                        lines = f.readlines()
                    target = url.strip()
                    if not target:
                        continue
                    target_lower = target.lower()
                    new_lines = [
                        line
                        for line in lines
                        if target not in line and target_lower not in line.lower()
                    ]
                    if len(new_lines) != len(lines):
                        with open(txt_file, 'w', encoding='utf-8') as f:
                            f.writelines(new_lines)
                        self.progress.emit(f"ğŸ—‘ï¸ Removed from {txt_file.name}")
                except Exception:
                    continue
        except Exception:
            pass

    def get_cookie_file(self, url, source_folder=None):
        """
        Return the most relevant cookies file for the given URL.

        Priority (in order):
        1. chrome_cookies.txt (Link Grabber master file)
        2. Platform-specific files (tiktok.txt, instagram.txt, etc.)
        3. Generic fallback (cookies.txt)
        4. Desktop fallback (toseeq-cookies.txt)

        Also stores all valid cookies in self._all_cookie_files for fallback attempts.
        """
        try:
            from modules.config.paths import get_cookies_dir

            candidates = []
            platform = _detect_platform(url)

            # Get persistent cookies directory
            cookies_dir = get_cookies_dir()

            # === PRIORITY 1: chrome_cookies.txt (Link Grabber saves here) ===
            master_cookie = cookies_dir / "chrome_cookies.txt"
            candidates.append(master_cookie)

            # === PRIORITY 2: Platform-specific cookies ===
            if platform != 'other':
                platform_cookie = cookies_dir / f"{platform}.txt"
                candidates.append(platform_cookie)

            # === PRIORITY 3: Generic fallback ===
            universal_cookie = cookies_dir / "cookies.txt"
            candidates.append(universal_cookie)

            # === PRIORITY 4: Desktop fallback (user convenience) ===
            desktop_cookie = Path.home() / "Desktop" / "toseeq-cookies.txt"
            candidates.append(desktop_cookie)

            # === PRIORITY 5: Source folder cookies (for bulk mode compatibility) ===
            if source_folder:
                folder_path = Path(source_folder)

                # Check source folder directly
                for name in ["chrome_cookies.txt", f"{platform}.txt", "cookies.txt"]:
                    candidate = folder_path / name
                    if candidate not in candidates:
                        candidates.append(candidate)

                # Check source_folder/cookies/ subdirectory
                cookies_sub = folder_path / "cookies"
                for name in ["chrome_cookies.txt", f"{platform}.txt", "cookies.txt"]:
                    candidate = cookies_sub / name
                    if candidate not in candidates:
                        candidates.append(candidate)

            # Find all valid cookie files
            valid_cookies = []
            for candidate in candidates:
                try:
                    if candidate and candidate.exists() and candidate.stat().st_size > 10:
                        valid_cookies.append(str(candidate))
                except Exception:
                    continue

            # Store for fallback use by other methods
            self._all_cookie_files = valid_cookies

            # Return first valid cookie (highest priority)
            if valid_cookies:
                return valid_cookies[0]

        except Exception:
            pass

        return None

    # -----------------------
    # ==== Download Methods per Platform ====

    def _method1_batch_file_approach(self, url, output_path, cookie_file=None):
        try:
            from datetime import datetime
            start_time = datetime.now()
            self.progress.emit(f"[{start_time.strftime('%H:%M:%S')}] ğŸš€ Method 1: YT-DLP Standard")

            # Smart yt-dlp detection
            ytdlp_cmd = self._get_ytdlp_command()
            if not ytdlp_cmd:
                self.progress.emit(f"   âš ï¸ yt-dlp not found, skipping command-based method")
                return False

            format_string = self.format_override or 'best'
            cmd = [
                ytdlp_cmd,  # Use detected command instead of hardcoded 'yt-dlp'
                '-o', os.path.join(output_path, '%(title)s.%(ext)s'),
                '--rm-cache-dir',
                '-f', format_string,
                '--restrict-filenames', '--no-warnings', '--retries', str(self.max_retries),
                '--continue', '--no-check-certificate',
                '--no-playlist',  # Don't download playlists
            ]
            if cookie_file:
                cmd.extend(['--cookies', cookie_file])
                self.progress.emit(f"   ğŸª Using cookies: {Path(cookie_file).name}")
            cmd.append(url)

            self.progress.emit(f"   â³ Starting download...")
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=1800, encoding='utf-8', errors='replace')

            elapsed = (datetime.now() - start_time).total_seconds()

            if result.returncode == 0:
                self.progress.emit(f"   âœ… SUCCESS in {elapsed:.1f}s")
                return True
            else:
                error_msg = result.stderr[:300] if result.stderr else "Unknown error"
                self.progress.emit(f"   âŒ FAILED ({elapsed:.1f}s)")
                self.progress.emit(f"   ğŸ“ Error: {error_msg}")
            return False
        except subprocess.TimeoutExpired:
            self.progress.emit(f"   â±ï¸ TIMEOUT (30min limit)")
            return False
        except Exception as e:
            self.progress.emit(f"   âŒ Exception: {str(e)[:100]}")
            return False

    def _method2_tiktok_special(self, url, output_path, cookie_file=None):
        """
        Enhanced TikTok download with:
        - IP block detection and retry
        - Proxy support
        - Better headers and user agent rotation
        - Rate limiting
        - Exponential backoff
        """
        try:
            if 'tiktok.com' not in url.lower():
                return False

            from datetime import datetime
            start_time = datetime.now()
            self.progress.emit(f"[{start_time.strftime('%H:%M:%S')}] ğŸµ TikTok Enhanced (Multi-Strategy)")

            # Apply rate limiting
            self._apply_rate_limit('tiktok.com')

            # UPDATED: Modern TikTok formats (2025) - old format IDs removed
            # Old 'http-264-hd-1' and 'http-264-hd-0' no longer work with new TikTok API
            tiktok_formats = [
                ('best[ext=mp4]/best', 'ğŸ¥ Best MP4'),
                ('bestvideo+bestaudio/best', 'ğŸ¬ Best Quality'),
                ('best', 'âœ¨ Best Available'),
            ]

            # Collect all available cookies
            cookie_files_to_try = []
            if cookie_file:
                cookie_files_to_try.append(cookie_file)

            if hasattr(self, '_all_cookie_files'):
                for cf in self._all_cookie_files:
                    if cf and cf not in cookie_files_to_try:
                        cookie_files_to_try.append(cf)

            if not cookie_files_to_try:
                cookie_files_to_try.append(None)

            # STRATEGY 1: Try direct download (fast, works 70% of time)
            self.progress.emit(f"   ğŸ“¥ Strategy 1: Direct download")
            result = self._try_tiktok_download(url, output_path, cookie_files_to_try,
                                               tiktok_formats, use_proxy=False, retry_count=0)
            if result['success']:
                elapsed = (datetime.now() - start_time).total_seconds()
                self.progress.emit(f"   âœ… SUCCESS ({elapsed:.1f}s) {result['message']}")
                return True

            # Check if IP blocked
            ip_blocked = result.get('ip_blocked', False)

            # STRATEGY 2: Try with proxy (if available and IP blocked)
            if ip_blocked and self.proxy_url:
                self.progress.emit(f"   ğŸŒ Strategy 2: Trying with proxy (IP block detected)")
                time.sleep(2)  # Brief delay before retry

                result = self._try_tiktok_download(url, output_path, cookie_files_to_try,
                                                   tiktok_formats, use_proxy=True, retry_count=0)
                if result['success']:
                    elapsed = (datetime.now() - start_time).total_seconds()
                    self.progress.emit(f"   âœ… SUCCESS via proxy ({elapsed:.1f}s) {result['message']}")
                    return True

            # STRATEGY 3: Retry with exponential backoff (if IP blocked)
            if ip_blocked:
                self.progress.emit(f"   ğŸ”„ Strategy 3: Retry with exponential backoff")

                for retry_attempt in range(2):  # Try 2 more times
                    wait_time = 2 ** (retry_attempt + 1)  # 2s, 4s
                    self.progress.emit(f"   â³ Waiting {wait_time}s before retry {retry_attempt + 1}/2...")
                    time.sleep(wait_time)

                    # Try with enhanced headers and random user agent
                    result = self._try_tiktok_download(url, output_path, cookie_files_to_try,
                                                       tiktok_formats, use_proxy=bool(self.proxy_url),
                                                       retry_count=retry_attempt + 1)
                    if result['success']:
                        elapsed = (datetime.now() - start_time).total_seconds()
                        self.progress.emit(f"   âœ… SUCCESS on retry {retry_attempt + 1} ({elapsed:.1f}s) {result['message']}")
                        return True

            # ALL STRATEGIES FAILED
            elapsed = (datetime.now() - start_time).total_seconds()
            self.progress.emit(f"   âŒ All strategies failed ({elapsed:.1f}s)")

            # Show specific error message
            if ip_blocked:
                self._show_tiktok_ip_block_help()
            else:
                self.progress.emit(f"   ğŸ’¡ Tips:")
                self.progress.emit(f"      â€¢ Make sure cookies/tiktok.txt exists")
                self.progress.emit(f"      â€¢ Video might be private or age-restricted")
                self.progress.emit(f"      â€¢ Try adding TikTok cookies (same as Link Grabber)")

            return False

        except Exception as e:
            self.progress.emit(f"   âŒ TikTok error: {str(e)[:100]}")
            return False

    def _try_tiktok_download(self, url, output_path, cookie_files, formats, use_proxy=False, retry_count=0):
        """
        Try TikTok download with given configuration
        Returns: {'success': bool, 'message': str, 'ip_blocked': bool}
        """
        # Smart yt-dlp detection
        ytdlp_cmd = self._get_ytdlp_command()
        if not ytdlp_cmd:
            return {
                'success': False,
                'message': 'yt-dlp command not found',
                'ip_blocked': False
            }

        last_error = ""
        ip_blocked = False

        for cookie_attempt_idx, current_cookie in enumerate(cookie_files, 1):
            if cookie_attempt_idx > 1:
                self.progress.emit(f"   ğŸ”„ Cookie {cookie_attempt_idx}/{len(cookie_files)}")
                if current_cookie:
                    self.progress.emit(f"   ğŸª Using: {Path(current_cookie).name}")

            for i, (fmt, desc) in enumerate(formats, 1):
                try:
                    # Only show format on first attempt to reduce noise
                    if retry_count == 0 and cookie_attempt_idx == 1:
                        self.progress.emit(f"   ğŸ”„ Format {i}/{len(formats)}: {desc}")

                    # Build command with enhanced headers
                    user_agent = _get_random_user_agent()

                    cmd = [
                        ytdlp_cmd,  # Use detected command
                        '-o', os.path.join(output_path, '%(title)s.%(ext)s'),
                        '-f', fmt,
                        '--no-playlist',
                        '--geo-bypass',
                        '--user-agent', user_agent,
                        '--restrict-filenames',
                        '--no-warnings',
                        '--retries', str(self.max_retries),
                        # Enhanced headers for better bot evasion
                        '--add-header', 'Accept:text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                        '--add-header', 'Accept-Language:en-US,en;q=0.9',
                        '--add-header', 'Accept-Encoding:gzip, deflate, br',
                        '--add-header', 'Referer:https://www.tiktok.com/',
                    ]

                    # Add proxy if requested
                    if use_proxy and self.proxy_url:
                        cmd.extend(['--proxy', self.proxy_url])

                    if current_cookie:
                        cmd.extend(['--cookies', current_cookie])

                    cmd.append(url)

                    result = subprocess.run(cmd, capture_output=True, text=True,
                                          timeout=300, encoding='utf-8', errors='replace')

                    if result.returncode == 0:
                        watermark_status = "ğŸ‰ NO WATERMARK!" if "hd-1" in fmt else ""
                        proxy_status = " via proxy" if use_proxy else ""
                        return {
                            'success': True,
                            'message': f"{watermark_status}{proxy_status}",
                            'ip_blocked': False
                        }
                    else:
                        # Check BOTH stdout and stderr (yt-dlp can use either)
                        error_output = (result.stderr or '') + (result.stdout or '')
                        last_error = error_output

                        # Show error on last attempt for debugging
                        if i == len(formats) and cookie_attempt_idx == len(cookie_files):
                            error_snippet = error_output[:150] if error_output else "Unknown error"
                            self.progress.emit(f"   âŒ Error: {error_snippet}")

                        # Check if IP blocked
                        if _is_ip_block_error(error_output):
                            ip_blocked = True

                except Exception as e:
                    last_error = str(e)
                    continue

        return {
            'success': False,
            'message': last_error[:100] if last_error else "Unknown error",
            'ip_blocked': ip_blocked
        }

    def _show_tiktok_ip_block_help(self):
        """Show helpful message when IP block detected"""
        self.progress.emit("")
        self.progress.emit("   â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
        self.progress.emit("   â•‘  ğŸš« TIKTOK IP BLOCK DETECTED                  â•‘")
        self.progress.emit("   â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        self.progress.emit("")
        self.progress.emit("   ğŸ”§ SOLUTIONS:")
        self.progress.emit("")
        self.progress.emit("   1ï¸âƒ£ Use VPN or Proxy:")
        self.progress.emit("      â€¢ Enable VPN on your computer")
        self.progress.emit("      â€¢ Or set proxy: export HTTPS_PROXY=socks5://127.0.0.1:1080")
        self.progress.emit("      â€¢ Try different proxy location")
        self.progress.emit("")
        self.progress.emit("   2ï¸âƒ£ Wait and Retry:")
        self.progress.emit("      â€¢ TikTok may have rate-limited your IP")
        self.progress.emit("      â€¢ Wait 15-60 minutes and try again")
        self.progress.emit("      â€¢ Temporary blocks usually expire")
        self.progress.emit("")
        self.progress.emit("   3ï¸âƒ£ Check Video Availability:")
        self.progress.emit("      â€¢ Video might be private/deleted")
        self.progress.emit("      â€¢ Try opening in browser first")
        self.progress.emit("      â€¢ Check if region-locked")
        self.progress.emit("")
        self.progress.emit("   ğŸ’¡ Quick fix: Switch to different network (WiFi â†” Mobile data)")
        self.progress.emit("")

    def _method3_optimized_ytdlp(self, url, output_path, cookie_file=None):
        try:
            from datetime import datetime
            start_time = datetime.now()
            self.progress.emit(f"[{start_time.strftime('%H:%M:%S')}] ğŸ”„ Method 3: yt-dlp with Cookies")

            format_string = self.format_override or 'best'
            ydl_opts = {
                'outtmpl': os.path.join(output_path, '%(title)s.%(ext)s'),
                'format': format_string,
                'quiet': True,
                'no_warnings': True,
                'retries': self.max_retries,
                'fragment_retries': self.max_retries,
                'continuedl': True,
                'nocheckcertificate': True,
                'restrictfilenames': True,
                'progress_hooks': [self._progress_hook],
            }

            if cookie_file:
                ydl_opts['cookiefile'] = cookie_file
                self.progress.emit(f"   ğŸª Using: {Path(cookie_file).name}")
            else:
                self.progress.emit(f"   âš ï¸ No cookies (may fail for private content)")

            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                ydl.download([url])

            elapsed = (datetime.now() - start_time).total_seconds()
            self.progress.emit(f"   âœ… SUCCESS in {elapsed:.1f}s")
            return True

        except Exception as e:
            elapsed = (datetime.now() - start_time).total_seconds() if 'start_time' in locals() else 0
            error_msg = str(e)
            self.progress.emit(f"   âŒ FAILED ({elapsed:.1f}s)")

            # Give specific hints based on error
            if 'login required' in error_msg.lower() or 'rate' in error_msg.lower():
                self.progress.emit(f"   ğŸ’¡ Hint: Need cookies for this content")
            elif 'private' in error_msg.lower():
                self.progress.emit(f"   ğŸ’¡ Hint: Content is private")

            self.progress.emit(f"   ğŸ“ Error: {error_msg[:200]}")
            return False

    def _method_instagram_enhanced(self, url, output_path, cookie_file=None):
        """Enhanced Instagram downloader with cookie validation and multiple fallbacks"""
        try:
            if 'instagram.com' not in url.lower():
                return False

            from datetime import datetime
            start_time = datetime.now()
            self.progress.emit(f"[{start_time.strftime('%H:%M:%S')}] ğŸ“¸ Instagram Enhanced Method")

            # IMPROVED: Collect ALL available cookie files to try
            cookie_files_to_try = []

            # Add primary cookie file
            if cookie_file and Path(cookie_file).exists():
                cookie_files_to_try.append(cookie_file)

            # Add other available cookies as fallback
            if hasattr(self, '_all_cookie_files'):
                for cf in self._all_cookie_files:
                    if cf and cf not in cookie_files_to_try and Path(cf).exists():
                        # Only add if file name suggests it might work for Instagram
                        if 'instagram' in Path(cf).name.lower() or 'cookies.txt' in Path(cf).name.lower():
                            cookie_files_to_try.append(cf)

            total_cookies = len(cookie_files_to_try)
            self.progress.emit(f"   ğŸª Found {total_cookies} cookie file(s) to try")

            # Try each cookie file
            for cookie_idx, current_cookie_file in enumerate(cookie_files_to_try, 1):
                if cookie_idx > 1:
                    self.progress.emit(f"   ğŸ”„ Trying alternate cookie file ({cookie_idx}/{total_cookies})")

                self.progress.emit(f"   ğŸª Using: {Path(current_cookie_file).name}")

                # Validate cookie
                cookie_is_valid = False
                validator = InstagramCookieValidator()
                validation = validator.validate_cookie_file(current_cookie_file)

                if validation['is_valid']:
                    self.progress.emit(f"   ğŸ”‘ Valid Instagram cookies!")
                    cookie_is_valid = True
                else:
                    self.progress.emit(f"   âš ï¸ Cookie validation failed:")
                    for error in validation['errors'][:1]:  # Show first error only
                        self.progress.emit(f"      â€¢ {error}")

                    if validation['is_expired']:
                        self.progress.emit(f"   ğŸ’¡ Cookies expired - trying next...")
                    elif not validation['has_sessionid']:
                        self.progress.emit(f"   ğŸ’¡ No sessionid found - trying next...")

                    # Try next cookie if validation failed
                    continue

                # Try download with validated cookie
                self.progress.emit(f"   ğŸ“¥ Attempting download...")

                # Smart yt-dlp detection
                ytdlp_cmd = self._get_ytdlp_command()
                if not ytdlp_cmd:
                    self.progress.emit(f"   âš ï¸ yt-dlp not found, skipping")
                    continue

                cmd = [
                    ytdlp_cmd,  # Use detected command
                    '-o', os.path.join(output_path, '%(title)s.%(ext)s'),
                    '--cookies', current_cookie_file,
                    '-f', 'best',
                    '--no-playlist',
                    '--restrict-filenames',
                    '--no-warnings',
                    url
                ]
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=300, encoding='utf-8', errors='replace')

                if result.returncode == 0:
                    elapsed = (datetime.now() - start_time).total_seconds()
                    self.progress.emit(f"   âœ… SUCCESS with {Path(current_cookie_file).name} ({elapsed:.1f}s)")
                    return True
                else:
                    error_snippet = result.stderr[:100] if result.stderr else "Unknown"
                    self.progress.emit(f"   âŒ Download failed: {error_snippet}")

            # If all cookie files failed, show helpful error message
            elapsed = (datetime.now() - start_time).total_seconds()
            self.progress.emit(f"   âŒ All cookie attempts failed ({elapsed:.1f}s)")
            self.progress.emit(f"   ")
            self.progress.emit(f"   â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
            self.progress.emit(f"   â•‘  ğŸ“¸ INSTAGRAM AUTHENTICATION REQUIRED         â•‘")
            self.progress.emit(f"   â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
            self.progress.emit(f"   ")
            self.progress.emit(f"   ğŸ”§ QUICK FIX:")
            self.progress.emit(f"   ")
            self.progress.emit(f"   1ï¸âƒ£ Same cookies work for Link Grabber & Downloader!")
            self.progress.emit(f"      â€¢ If Link Grabber works, Downloader will too")
            self.progress.emit(f"      â€¢ Export cookies to: cookies/instagram.txt")
            self.progress.emit(f"   ")
            self.progress.emit(f"   2ï¸âƒ£ How to export cookies:")
            self.progress.emit(f"      a) Install browser extension:")
            self.progress.emit(f"         'Get cookies.txt LOCALLY'")
            self.progress.emit(f"      b) Login to Instagram in browser")
            self.progress.emit(f"      c) Click extension â†’ Export")
            self.progress.emit(f"      d) Save as: cookies/instagram.txt")
            self.progress.emit(f"   ")
            self.progress.emit(f"   3ï¸âƒ£ Make sure:")
            self.progress.emit(f"      â€¢ You're logged into Instagram in browser")
            self.progress.emit(f"      â€¢ Cookies are NOT expired (< 30 days old)")
            self.progress.emit(f"      â€¢ File contains 'sessionid' cookie")
            self.progress.emit(f"   ")
            self.progress.emit(f"   ğŸ’¡ Checked {total_cookies} cookie file(s) - all invalid/expired")
            self.progress.emit(f"   ")
            return False

        except Exception as e:
            self.progress.emit(f"   âŒ Instagram enhanced error: {str(e)[:100]}")
            return False

    def _method_instaloader(self, url, output_path, cookie_file=None):
        try:
            if 'instagram.com' not in url.lower():
                return False
            try:
                import instaloader
            except ImportError:
                self.progress.emit("âš ï¸ Instaloader not installed; skipping fallback")
                return False

            self.progress.emit("ğŸ“¸ Instaloader fallback")
            match = re.search(r"instagram\.com/(?:p|reel|tv)/([^/?#&]+)", url, re.IGNORECASE)
            if not match:
                self.progress.emit("âš ï¸ Could not detect Instagram shortcode for Instaloader")
                return False

            shortcode = match.group(1)
            loader = instaloader.Instaloader(
                dirname_pattern=os.path.join(output_path, "{target}"),
                filename_pattern="{shortcode}",
                download_videos=True,
                download_video_thumbnails=False,
                download_pictures=False,
                download_comments=False,
                save_metadata=False,
                quiet=True,
                compress_json=False,
            )

            if cookie_file:
                try:
                    cookies_dict = {}
                    with open(cookie_file, 'r', encoding='utf-8', errors='ignore') as handle:
                        for line in handle:
                            stripped = line.strip()
                            if not stripped or stripped.startswith('#'):
                                continue
                            parts = stripped.split('\t')
                            if len(parts) >= 7:
                                cookies_dict[parts[5]] = parts[6]
                    if cookies_dict:
                        loader.context._session.cookies.update(cookies_dict)
                except Exception as cookie_error:
                    self.progress.emit(f"âš ï¸ Instaloader cookie load failed: {str(cookie_error)[:60]}")

            post = instaloader.Post.from_shortcode(loader.context, shortcode)
            target = post.owner_username or "instagram"
            loader.download_post(post, target=target)
            self.progress.emit("âœ… Instaloader SUCCESS")
            return True
        except Exception as e:
            self.progress.emit(f"âš ï¸ Instaloader error: {str(e)[:100]}")
            return False

    def _method_gallery_dl(self, url, output_path, cookie_file=None):
        """gallery-dl fallback for Instagram, Twitter, etc."""
        try:
            self.progress.emit("ğŸ–¼ï¸ gallery-dl fallback")
            cmd = [
                'gallery-dl',
                '--dest', output_path,
                '--filename', '{title}_{id}.{extension}',
                '--no-mtime',
            ]

            if cookie_file:
                cmd.extend(['--cookies', cookie_file])
                self.progress.emit(f"ğŸª Using cookies: {Path(cookie_file).name}")

            cmd.append(url)

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=600,
                encoding='utf-8',
                errors='replace'
            )

            if result.returncode == 0:
                self.progress.emit("âœ… gallery-dl SUCCESS!")
                return True
            else:
                error_msg = result.stderr[:200] if result.stderr else "Unknown error"
                self.progress.emit(f"âš ï¸ gallery-dl failed: {error_msg}")
                return False

        except subprocess.TimeoutExpired:
            self.progress.emit("âš ï¸ gallery-dl timeout")
            return False
        except FileNotFoundError:
            self.progress.emit("âš ï¸ gallery-dl not installed")
            return False
        except Exception as e:
            self.progress.emit(f"âš ï¸ gallery-dl error: {str(e)[:100]}")
            return False

    def _method6_youtube_dl_fallback(self, url, output_path, cookie_file=None):
        """youtube-dl as final fallback (older but sometimes works)"""
        try:
            self.progress.emit("ğŸ”„ youtube-dl fallback (legacy)")
            format_string = self.format_override or 'best'
            cmd = [
                'youtube-dl',
                '-o', os.path.join(output_path, '%(title)s.%(ext)s'),
                '-f', format_string,
                '--no-warnings',
                '--retries', str(self.max_retries),
                '--continue',
                '--no-check-certificate'
            ]

            if cookie_file:
                cmd.extend(['--cookies', cookie_file])

            cmd.append(url)

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=900,
                encoding='utf-8',
                errors='replace'
            )

            if result.returncode == 0:
                self.progress.emit("âœ… youtube-dl SUCCESS!")
                return True
            else:
                self.progress.emit("âš ï¸ youtube-dl failed")
                return False

        except subprocess.TimeoutExpired:
            self.progress.emit("âš ï¸ youtube-dl timeout")
            return False
        except FileNotFoundError:
            self.progress.emit("âš ï¸ youtube-dl not installed")
            return False
        except Exception as e:
            self.progress.emit(f"âš ï¸ youtube-dl error: {str(e)[:100]}")
            return False

    def _method4_alternative_formats(self, url, output_path, cookie_file=None):
        try:
            self.progress.emit("ğŸ”„ Method 4: Alternative formats")
            format_options = ['best[ext=mp4]', 'bestvideo+bestaudio', 'best']
            if self.format_override and self.format_override not in format_options:
                format_options.insert(0, self.format_override)
            elif self.format_override:
                # Prioritize selected format
                format_options.remove(self.format_override)
                format_options.insert(0, self.format_override)
            for fmt in format_options:
                try:
                    ydl_opts = {
                        'outtmpl': os.path.join(output_path, '%(title)s.%(ext)s'),
                        'format': fmt,
                        'quiet': True, 'no_warnings': True, 'retries': self.max_retries,
                        'continuedl': True, 'nocheckcertificate': True, 'restrictfilenames': True,
                    }
                    if cookie_file: ydl_opts['cookiefile'] = cookie_file
                    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                        ydl.download([url])
                    self.progress.emit(f"âœ… Method 4 SUCCESS (format: {fmt})")
                    return True
                except Exception:
                    continue
            self.progress.emit("âš ï¸ Method 4 failed")
            return False
        except Exception as e:
            self.progress.emit(f"âš ï¸ Method 4 error: {str(e)[:100]}")
            return False

    def _method5_force_ipv4(self, url, output_path, cookie_file=None):
        try:
            self.progress.emit("ğŸ”„ Method 5: Force IPv4 fallback")

            # Smart yt-dlp detection
            ytdlp_cmd = self._get_ytdlp_command()
            if not ytdlp_cmd:
                self.progress.emit(f"   âš ï¸ yt-dlp not found, skipping")
                return False

            format_string = self.format_override or 'best'
            cmd = [
                ytdlp_cmd,  # Use detected command
                '-o', os.path.join(output_path, '%(title)s.%(ext)s'),
                '-f', format_string,
                '--force-ipv4', '--no-warnings', '--geo-bypass',
                '--retries', str(self.max_retries), '--ignore-errors', '--continue',
                '--restrict-filenames', '--no-check-certificate'
            ]
            if cookie_file:
                cmd.extend(['--cookies', cookie_file])
                self.progress.emit(f"ğŸª Using cookies: {Path(cookie_file).name}")
            cmd.append(url)
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=900,
                encoding='utf-8',
                errors='replace'
            )
            if result.returncode == 0:
                self.progress.emit("âœ… Method 5 SUCCESS!")
                return True
            error_msg = result.stderr[:200] if result.stderr else "Unknown error"
            self.progress.emit(f"âš ï¸ Method 5 failed: {error_msg}")
            return False
        except subprocess.TimeoutExpired:
            self.progress.emit("âš ï¸ Method 5 timeout")
            return False
        except Exception as e:
            self.progress.emit(f"âš ï¸ Method 5 error: {str(e)[:100]}")
            return False

    def _progress_hook(self, d):
        try:
            if self.cancelled:
                raise Exception("Cancelled by user")
            if d['status'] == 'downloading':
                speed = d.get('speed', 0)
                if speed:
                    speed_mb = speed / (1024 * 1024)
                    self.download_speed.emit(f"{speed_mb:.2f} MB/s")
                eta = d.get('eta', 0)
                if eta:
                    mins, secs = divmod(eta, 60)
                    self.eta.emit(f"{int(mins)}m {int(secs)}s")
                downloaded = d.get('downloaded_bytes', 0)
                total = d.get('total_bytes') or d.get('total_bytes_estimate', 0)
                if total > 0:
                    percent = int((downloaded / total) * 100)
                    self.progress_percent.emit(percent)
        except Exception:
            pass

    # ---- MAIN DOWNLOAD LOOP ----

    def run(self):
        try:
            if not self.urls:
                self.finished.emit(False, "âŒ No URLs provided")
                return
            total = len(self.urls)

            # Show mode clearly
            mode_name = "ğŸ”¹ BULK MODE" if self.is_bulk_mode else "ğŸ”¸ SINGLE MODE"
            self.progress.emit("="*60)
            self.progress.emit(f"ğŸš€ SMART DOWNLOADER STARTING - {mode_name}")
            self.progress.emit(f"ğŸ“Š Total links: {total}")

            if self.is_bulk_mode:
                self.progress.emit(f"ğŸ“‚ Creators: {len(self.bulk_creators)}")
                self.progress.emit("âœ… History tracking: ON")
                self.progress.emit("âœ… Auto URL cleanup: ON")
                self.progress.emit(f"ğŸ“ Track file: {self.downloaded_links_file.name}")
            else:
                self.progress.emit("ğŸ“ Save: Desktop/Toseeq Downloads")
                self.progress.emit("âš¡ Simple mode: No tracking, no extra files")
                self.progress.emit("ğŸš« File creation: DISABLED")
                # Clean up any leftover tracking files from old runs
                self._cleanup_tracking_files(self.save_path)

            self.progress.emit("="*60)
            if self.force_all_methods:
                self.progress.emit("ğŸ›¡ï¸ Multi-strategy fallback enabled")
            # Map URLs to their source folder by looking up all *.txt in save_path (recursive)
            url_folder_map = {}
            for root, dirs, files in os.walk(self.save_path):
                for fname in files:
                    if fname.endswith(".txt") and not fname.startswith('.'):
                        txt_path = Path(root) / fname
                        try:
                            with open(txt_path, 'r', encoding='utf-8', errors='ignore') as f:
                                for line in f:
                                    raw_url = line.strip()
                                    if not raw_url:
                                        continue
                                    key = normalize_url(raw_url)
                                    if key:
                                        url_folder_map[key] = root
                        except Exception:
                            continue
            # Fallback: direct URLs go to main save_path
            for url in self.urls:
                key = normalize_url(url)
                if key not in url_folder_map:
                    url_folder_map[key] = self.save_path
            processed = 0
            for url in self.urls:
                if self.cancelled: break
                folder = url_folder_map.get(normalize_url(url), self.save_path)
                os.makedirs(folder, exist_ok=True)
                # Skip logic handled by history.json in bulk mode
                processed += 1
                if self._is_already_downloaded(url):
                    self.progress.emit(f"â­ï¸ [{processed}/{total}] Already downloaded, skipping...")
                    self.skipped_count += 1
                    continue
                self.progress.emit(f"\nğŸ“¥ [{processed}/{total}] {url[:80]}...")
                cookie_file = self.get_cookie_file(url, folder)
                # Platform-wise methods with enhanced fallbacks
                platform = _detect_platform(url)
                if platform == 'tiktok':
                    methods = [
                        self._method2_tiktok_special,
                        self._method1_batch_file_approach,
                        self._method3_optimized_ytdlp,
                        self._method4_alternative_formats,
                        self._method5_force_ipv4,
                        self._method6_youtube_dl_fallback,
                    ]
                elif platform == 'instagram':
                    methods = [
                        self._method_instagram_enhanced,  # NEW: Try browser cookies first
                        self._method1_batch_file_approach,
                        self._method3_optimized_ytdlp,
                        self._method_gallery_dl,
                        self._method_instaloader,
                        self._method4_alternative_formats,
                    ]
                elif platform == 'twitter':
                    methods = [
                        self._method1_batch_file_approach,
                        self._method3_optimized_ytdlp,
                        self._method_gallery_dl,
                        self._method4_alternative_formats,
                        self._method5_force_ipv4,
                    ]
                else:
                    methods = [
                        self._method1_batch_file_approach,
                        self._method3_optimized_ytdlp,
                        self._method4_alternative_formats,
                        self._method5_force_ipv4,
                        self._method6_youtube_dl_fallback,
                    ]

                # Force all methods adds extras
                if not self.force_all_methods:
                    # Limit to first 3-4 methods for speed
                    methods = methods[:4]
                # Try all methods
                success = False
                for method in methods:
                    if self.cancelled: break
                    try:
                        if method(url, folder, cookie_file):
                            success = True
                            break
                    except Exception as e:
                        self.progress.emit(f"Method error: {str(e)[:100]}")
                if success:
                    self.success_count += 1
                    self.progress.emit(f"âœ… [{processed}/{total}] Downloaded!")
                    self._mark_as_downloaded(url)
                    self._remove_from_source_txt(url, folder)
                    # Timestamp tracking handled by history.json
                    self.video_complete.emit(url)
                else:
                    self.progress.emit(f"âŒ [{processed}/{total}] ALL METHODS FAILED")
                pct = int((processed / total) * 100)
                self.progress_percent.emit(pct)
            self.progress.emit("\n" + "="*60)
            self.progress.emit("ğŸ“Š FINAL REPORT:")
            self.progress.emit(f"âœ… Successfully downloaded: {self.success_count}")
            self.progress.emit(f"â­ï¸ Skipped (already done): {self.skipped_count}")
            self.progress.emit(f"âŒ Failed: {total - self.success_count - self.skipped_count}")
            self.progress.emit("="*60)

            # Update history.json for bulk mode
            if self.history_manager and self.bulk_creators:
                self.progress.emit("\nğŸ“ Updating download history...")
                try:
                    # Track downloads per creator
                    creator_stats = {}  # {creator: {'success': 0, 'failed': 0}}

                    # Count successes/failures per creator
                    for creator, creator_info in self.bulk_creators.items():
                        # === FIX: Normalize creator links for accurate matching ===
                        raw_links = creator_info.get('links', [])
                        creator_links_normalized = set(normalize_url(link) for link in raw_links)

                        success = 0
                        failed = 0

                        for url in self.urls:
                            # === FIX: Normalize current URL for comparison ===
                            url_normalized = normalize_url(url)

                            # Now comparison will work correctly
                            if url_normalized in creator_links_normalized:
                                # FIX: Check using NORMALIZED url (downloaded_links contains normalized URLs)
                                if url_normalized in self.downloaded_links:
                                    success += 1
                                else:
                                    failed += 1

                        creator_stats[creator] = {'success': success, 'failed': failed}

                    # Update history for each creator
                    for creator, stats in creator_stats.items():
                        status = 'success' if stats['failed'] == 0 else ('partial' if stats['success'] > 0 else 'failed')
                        self.history_manager.update_creator(
                            creator,
                            downloaded_count=stats['success'],
                            failed_count=stats['failed'],
                            status=status
                        )
                        self.progress.emit(f"  âœ“ {creator}: {stats['success']} downloaded, {stats['failed']} failed")

                        # Remove successfully downloaded URLs from links file
                        if stats['success'] > 0:
                            links_file = self.bulk_creators[creator].get('links_file')
                            if links_file and Path(links_file).exists():
                                try:
                                    # Read current content
                                    with open(links_file, 'r', encoding='utf-8', errors='ignore') as f:
                                        lines = f.readlines()

                                    # Filter out downloaded links
                                    new_lines = []
                                    for line in lines:
                                        url_in_line = line.strip()
                                        if not url_in_line or url_in_line.startswith('#'):
                                            new_lines.append(line)
                                            continue

                                        # Check if this URL was downloaded
                                        is_downloaded = False
                                        for dl_url in self.downloaded_links:
                                            if url_in_line in dl_url or dl_url in url_in_line:
                                                is_downloaded = True
                                                break

                                        if not is_downloaded:
                                            new_lines.append(line)

                                    # Write back
                                    with open(links_file, 'w', encoding='utf-8') as f:
                                        f.writelines(new_lines)

                                    self.progress.emit(f"  ğŸ—‘ï¸ Updated {Path(links_file).name}")
                                except Exception as e:
                                    self.progress.emit(f"  âš ï¸ Failed to update {Path(links_file).name}: {str(e)[:50]}")

                    self.progress.emit("âœ… History updated!")
                except Exception as e:
                    self.progress.emit(f"âš ï¸ History update failed: {str(e)[:100]}")

            if self.cancelled:
                self.finished.emit(False, f"âš ï¸ Cancelled - {self.success_count} downloaded")
            elif self.success_count + self.skipped_count == total:
                self.finished.emit(True, f"âœ… ALL DONE! {self.success_count} new, {self.skipped_count} skipped")
            elif self.success_count > 0:
                self.finished.emit(True, f"âš ï¸ Partial: {self.success_count} downloaded, {self.skipped_count} skipped")
            else:
                self.finished.emit(False, f"âŒ Failed - 0 downloaded")
        except Exception as e:
            self.progress.emit(f"âŒ CRITICAL ERROR: {str(e)[:200]}")
            self.finished.emit(False, f"âŒ Error: {str(e)[:100]}")

    def cancel(self):
        self.cancelled = True
        self.progress.emit("âš ï¸ Cancellation requested...")
